This chapter describes a heuristic algorithm to solve the 3D bin packing problem with vertical support.
In section \ref{sec:problem_state} we describe the concepts which will be used in the algorithm, like the definition of a state, insertions, and the feasibility of a solution.
Since the 3D-BPP is NP-Hard, an exhaustive search for a solution is not practical, so a heuristic search is conducted by combining the beam search algorithm described in \cref{sec:beamsearch} with the constructive heuristic described in \cref{sec:support_planes}.
The proposed algorithm takes in input the empty state (\ref{def:empty_state}), and outputs the best state based on an ordering function defined in section \ref{ssec:scoring_states}.

\section{States}
\label{sec:problem_state}%
States or packings are partial solutions to the 3D-BPPWS. Since our heuristic is constructive by nature, the main idea of the algorithm is that by starting from a state representing an empty solution, we'll iteratively build new states that are always closer to a complete solution to the problem.
Given the formal definition of the problem (\ref{sec:milp}) we introduce a few new definitions to facilitate the algorithm's definition.
First, it is helpful to define a collection of items that still need to be assigned to a particular bin; this collection would then be used to track how many items still need to be placed.
Let us define the concept of unpacked items in relation to our MILP formulation.
\begin{definition}[Unpacked item]
    An item $i \in I$ is unpacked \textbf{iff}
    \begin{equation*}
        \sum_{b \in B} u_{ib} = 0
    \end{equation*}
\end{definition}

It is also assumed that variables identifying an item's position are independent between states (changes to their values in state $s$ won't affect state $s^\prime$).
In order to simplify the algorithm representation, rotations are handled by simply swapping the dimensions $w_i$ and $d_i$ of item $i \in I$ when needed.
A state $s$ can then be defined as follows:
\begin{itemize}
    \item $U$: the set of unpacked items,
    \item $B$: the set of used bins,
    \item $Q = (q_1, q_2,\dots, q_b)$: the set of supporting structures for each bin $b \in B$,
    \item $p$: the insertion pending on this state (described by def. \ref{def:insertion}).
\end{itemize}

Since the heuristic will open new bins when the already opened ones are full, the number of bins in each state can vary and is not fixed as a parameter to the problem like in the MILP formulation.
Thanks to the newly introduced definitions, we can trivially define a function that determines if a state is a final state.
\begin{definition}
    \label{def:state_final}
    A state $s$ is final if there are no more items to pack
    \begin{equation}
        \label{algo:state_final}%
        IsFinal(s) = \left\{\begin{aligned}
            1,\hspace{0.5cm}& s.U = \emptyset \\
            0,\hspace{0.5cm}& \text{otherwise}
        \end{aligned}
        \right.
    \end{equation}
\end{definition}

The proposed heuristic also stores additional data for each opened bin, which will then be used by the constructive heuristic described in \cref{sec:support_planes}.
This additional information is stored in the set $s.Q$ so that each bin $b \in B$ has an associated supporting structure $q_b \in s.Q$.
The collection of items placed inside a bin, for example, is one piece of data that we store in this structure.
Let us then introduce the concept of packed items inside a bin.
\begin{definition}[Packed item]
    Given a state $s$ and a bin $b \in s.B$, we say that item
    \begin{equation*}
        \begin{aligned}
            i \in I \hspace{.2cm}\text{is packed in} \hspace{.2cm}b \hspace{.2cm}& \textbf{iff} \hspace{.2cm}& u_{ib} = 1
        \end{aligned}
    \end{equation*}
\end{definition}

In addition to the set of packed items, other supporting structures are needed to facilitate checks of the problem's constraints.
Given a bin $b \in s.B$ we can then define structure $q_b$ as follows.
\begin{itemize}
    \item $J$: the set of items that are packed inside $b$,
    \item $Z$: the set of planes inside $b$ (section \ref{sec:support_planes}),
    \item $T$: the AABB Tree (section \ref{sec:problem_state:aabbtree}) representing the items inside $b$.
\end{itemize}

Both sets $q_b.J$ and $q_b.T$ contain the items packed in $b$ but adding and accessing items in $q_b.J$ has a time complexity of $O(1)$ given an implementation as hash set while maintaining $q_b.T$ usually has a time complexity of $O(log(|q_b.J|))$.

\subsection{AABB Tree}
\label{sec:problem_state:aabbtree}%

To determine the feasibility of a given state, checking for overlaps with items already placed is needed.
Since every item is a cuboid and our problem formulation only allows for $90\deg$ rotations over the z-axis, each item is contained inside a bounding box, which is axis-aligned.
An adequate structure to compute overlaps is then an Axis-Aligned Bounding Box Tree (AABB Tree) \citep{bergen1997efficient}.

AABB Trees are bounding volume hierarchies typically used for fast collision detection, and they usually offer a few operations:
\begin{itemize}
    \item $AABBInsert(i)$: which allows inserting an axis-aligned box $i$ in the tree
    \item $AABBOverlaps(i)$: which allows determining if an axis-aligned box $i$ overlaps an element in the tree
    \item $AABBClosest(i, d)$: which, given an axis-aligned box $i$ and an axis-aligned direction $d$, returns the closest element following that direction starting from the box $i$
\end{itemize}

If the tree is appropriately balanced, each operation, on average, has a time complexity of $O(log(n))$ where $n$ is the number of elements in the tree.
Maintaining an AABB Tree in the state allows us to do checks for feasibility during the construction of a solution (as detailed in \ref{ssec:scoring_insertions} ) and feasibility checks on the final states to allow for error detection.

\label{aabb:get_supporting}%
An additional opertation $AABBGetSupporting(i, \beta_s)$ was added to compute the set of supporting boxes of item $i$ given a vertical tolerance $\beta_s$.
This was possible by only checking intersections over the XY-plane similarly to the $AABBOverlaps$ implementation and filtering each item by the distance with tolerance.

\subsection{Feasibility}
\label{sec:problem_state:feasibility}%
A state $s$ is feasible if the currently packed items in each bin $b \in s.B$ aren't overlapping any other item if they are all contained inside their bin and if each item is either on the ground or satisfies at least one of the support conditions (cond. \ref{support:area_support}, cond. \ref{support:vertex_support}).
Since the proposed heuristic is constructive, it is more convenient to define the concept of feasibility relative to a change in the state.
In the heuristic, we generate new states by applying insertions starting from an initial feasible one. Let us define the concept of insertion and how an insertion is feasible.

\begin{definition}[Insertion]
    \label{def:insertion}%
    Given a state $s$, we define an insertion $p$ as a tuple $(b, I)$ where $b \in s.B$, and $I$ is a set of non-overlapping unpacked items such that they are inserted at the same $z$.
    \begin{equation*}
        \label{eq:insertion_same_z}
        I \subseteq s.U \land \exists z (z \in \mathbb{Z} \land \forall i ( i \in I \land z_i = z))
    \end{equation*}
\end{definition}
\begin{observation}
    \label{oss:state_bin_open}
    Given a state $s$ and an insertion $p = (b, \emptyset)$ where $b \notin s.B$, $p$ is an insertion that opens a new bin $b$ in $s$.
\end{observation}

\begin{definition}[Next]
    \label{def:state_next}%
    Let $p$ be an insertion over a state $s$, we define $s^\prime = Next(s, p)$ as a "copy" of state $s$ where $p$ is the pending insertion ($s^\prime.p = p$).
\end{definition}

We evaluate the changes to the score of a state based on its pending insertion. 
In this way, we don't have to update all the structures for every evaluated state. 
In addition, this property let us do fewer memory clones of states that would have been discarded either way (as seen in \cref{sec:beamsearch}). 
We can then define an algorithm that applies a pending insertion $p$ on a given state $s$ with the help of a function $OpenBin(b)$ which initializes a new structure $q_b$ with every element at its empty value.
The proposed algorithm is shown in \ref{algo:state_commit}.

\input{algorithms/state_commit}

\paragraph*{Insertion feasibility}
An insertion $p = (b, I)$ that is pending on a given state $s$ is feasible if every inserted item $i \in p.I$ satisfies the constraint of non-overlap (\ref{cons:no_overlap}), the constraint of support (\ref{cons:every_item_is_supported}) and if it is placed within the bin.
Given an item from the set of the inserted items $i \in p.I$, and the AABB tree for bin $p.b$ in the current state $q_b.T$ as $T$.
Let $I_{\text{support}}$ be the set of items that could support item $i$ when placed in the bin, which could be saved in an appropriate structure or computed through the AABB tree as defined in \cref{aabb:get_supporting}.

Let $HasSupport(i, I_{\text{support}})$ be the function that returns true if the considered item would verify at least one of the conditions of support (cond. \ref{support:area_support} or cond. \ref{support:vertex_support}) or false otherwise.
We can define a function $IsFeasible(i, I_{\text{support}}, T)$ which returns true if the insertion of $i$ in bin $b$ for state $s$ is feasible and false otherwise. 
If every item $i \in p.I$ is feasible and every item in $I$ is not overlapping the others, then insertion $p$ is feasible.
In case some items in $p$ aren't feasible we can always define a function $RemoveInfeasibleItems(p, I_{\text{support}}, T)$ which removes every unfeasible item and returns a new insertion $p^\prime = (b, I^\prime)$ where $I^\prime = p.I \setminus \{i \in p.I : \lnot IsFeasible(i, I_{\text{support}}, T)\}$. \label{algo:remove_infeasible}

Checking if a state is feasible can then be done by iteratively applying all the insertions ordered by z and updating the proper trees, or starting from an already built tree and computing the set $I_{\text{support}}$ for each item through the tree as defined in \ref{aabb:get_supporting}.
\begin{proposition}
    \label{prop:feasible_expansion}
    A state $s^\prime$ derived by committing a feasible insertion $p$ to a feasible state $s$ is feasible.
\end{proposition}

\begin{observation}
    \label{def:empty_state}
    We can always define the empty state $s_e$ where \begin{equation*}
        \left\{ 
            \begin{aligned}
            s_e.U & = I \\
            s_e.Q & = \emptyset \\
            s_e.B & = \emptyset
            \end{aligned}
        \right.
    \end{equation*}
    and it is always feasible
\end{observation}

\subsection{State Hashing}
\label{sec:state_uniqueness}%
From a given state, it's possible to apply two different sequences of insertions and end up with two states that have all the items in the same positions.
This undesirable behavior was observed during our computational experiments.
A hashing mechanism needs to be introduced to enable checking if two states are likely the same in constant time.
In a state $s$ we can identify a packed item $i \in I$ in a given position $(x_i, y_i, z_i)$ with its given dimensions $(w_i, d_i, z_i)$ in a given bin $b \in s.B$ with a non-commutative hashing function $hash\_nc$. 
The resulting hash $hash_{ib} = hash\_nc(b, x_i, y_i, z_i, w_i, d_i, h_i)$ can identify every similar packing of an item of the same shape in that specific bin spot.
Since $hash_{ib}$ identifies one item with the shape of $i$ in the same spot as $i$, we can use a commutative function to combine every hash for every packed item in every bin to ignore the order with which items were added to the solution.
The combined hash can then be saved inside the state structure as follows. 
\begin{equation}
    s.hash = \sum\limits_{b \in s.B}{\sum\limits_{i \in q_b.J}{hash_{ib}}}
\end{equation}
In our tests, by filtering states with the proposed hash as seen in algo. \ref{algo:beamsearch}, with a simple 64-bit hashing function, this mechanism allowed us to filter out all equal states between iterations with a low amount of collisions.
Since the combining of hashes is a simple sum with modulus, the hashing of the state can also be kept updated in constant time at each iteration by simply adding the inserted hashes in the $Commit$ function (algo. \ref{algo:state_commit}).

%TODO: Do a grammar pass
\section{Beam Search}
\label{sec:beamsearch}%
%TODO: maybe add info on literature  (search about Bisiani)
Beam Search (BS) is a heuristic tree search algorithm designed for systems with limited memory where expanding every possible node is unfeasible.
The idea behind BS is to conduct an iterative truncated breadth-first search where, at each iteration, only a limited number of $k$ nodes is expanded.
After the expansion, every new node needs to be evaluated and sorted to prune the number of nodes down to the $k$ best ones. The algorithm keeps exploring until no further node can be expanded.

To perform BS one must define the node structure, an expansion function to generate new nodes from existing ones, a ranking between nodes, and a function to determine if a node is final.

A node in the tree can be represented as the state in \cref{sec:problem_state} and \cref{algo:state_final} can be used to determine if a state is final. We also know that a new state $s^\prime$ derived by $s$ by applying a feasible insertion $p$ can be computed as in \cref{def:state_next}.
This state expansion procedure, with the exception of empty insertions, will generate new states in our tree which will add a positive number of bins or packed items to the solution so, eventually, it will generate a final state.

If the starting state for the search is feasible every new state generated will be feasible and if a final state is found it will be feasible ( \cref{prop:feasible_expansion}).
We also note that starting from state $s$ the time complexity to compute feasible insertions can be lower than the complexity required to update the structures that will be used for further expansions (AABB Tree insertion and balancing, memory cloning, etc.) so we modified the standard BS algorithm to separate the expansion phase from the commit phase.
As noted in \cref{sec:state_uniqueness}, since by evaluating different insertions on different states it is possible to end up having two equal states, a filtering mechanism should be introduced.
During each iteration, it is possible to keep the hashes of the best selected states in a hash set and discard new states with the same hash.

Given a set of initial states $S^0$ and the number of best states to expand at each iteration $k$, the described BS can be represented by algorithm \ref{algo:beamsearch}.
As observed in \cref{def:empty_state}, it's possible to start the search from $S^0 = \{ s_e \}$.

\input{algorithms/beamsearch}

\paragraph*{State Expansion}

An expansion of a state $s$ can be seen as a new set of states $S_{new}$ derived by a set of feasible insertions.
In order to determine these insertions, an underlying heuristic is used (described in \cref{sec:support_planes}).

The main idea in this phase of the algorithm is to find feasible insertions in all the bins at the lowest possible height for items that still need to be packed.
To reduce the number of possible expansions to evaluate we limit the search to insertions of items with unique shapes.
With a similar concept to the one used in \cref{sec:state_uniqueness}, an hash for each item's dimensions can be computed on the fly or pre-computed as a problem's parameter.
Given each item's hash we can then group items that have the same shape.
The evaluation of new insertions can then be done with two different approaches:
\begin{itemize}
    \label{def:placement_modes}%
    \item \textbf{PS}: where we evaluate only the possible insertion of a single item per item type, which would generate insertions of at most 1 item,
    \item \textbf{PM}: where we evaluate the biggest possible insertion of a group of items of the same shape, which would generate insertions of at most the size of the group of items with the same shape.
\end{itemize}
Creating insertions of groups of similar items is usually used in Pallet Loading Problems (as for ex. \citep{elhedhli2019three}) to create better bases of support for upper layers.
With a similar intuition, the idea of placing groups of items of the same shape is to facilitate the creation of uniform planes (not necessarily layers) to use for further insertions.

Given a set of items $I$ and a tolerance $\beta_s$ we can introduce an algorithm to group them by their shape and produce a set $G$ of tuples $(h, I^\prime)$ where $h$ is the hash summurizing the shape of the group and $I^\prime$ is the set of items grouped as in algo. \ref{algo:group_by_hash}.
Once items are grouped by shape the best insertion for each class of items can be computed for each open bin. If no insertion is possible in any bin, then the only viable insertion is the bin opening insertion (\cref{oss:state_bin_open}).
The described procedure is detailed in algo. \ref{algo:state_successor}, which can be modified with minor changes to limit the number of items to consider when in PS mode.

\input{algorithms/state_successor}
\input{algorithms/group_by_height}


\subsection{Sorting States}
\label{ssec:scoring_states}%
In order to sort states, an ordering needs to be defined over them.
Since the selection of a state over an other is what will influence the final solution the most, parameters that are directly related to minimizing the objective function are used.

In the proposed solution to handle multiple objective functions, lexicographic ordering is used.
\begin{definition}
    \label{def:lexicographic_ordering}
    Let $f_1(s), f_2(s), f_i(s), \dots, f_n(s)$ be objective functions ordered by precedence based on index $i \in \mathbb{Z}$, then 
    \begin{equation*}
        s < s^\prime \hspace{.2cm} \textbf{iff} \hspace{.2cm} \exists j \in \mathbb{Z} : \left\{
            \begin{aligned}
                f_j(s) < f_j(s^\prime) & \\
                f_k(s) = f_k(s^\prime) &,\hspace{.5cm} \forall k \in \mathbb{Z} : 0 \le k < j 
            \end{aligned}
        \right.
    \end{equation*}
\end{definition}

Scoring metrics for each state $s$ that we want to evaluate can then be computed in the $Next$ algorithm by considering the contents of the pending insertions and updating each parameter differentially.

The defined ordering utilized is the following:
\begin{itemize}
    \item $f_1(s) = -|s.B|$: we prefer states that opened fewer bins.
    \item $f_2(s) = \text{avgvol}(s)$: we prefer states that have packed more average volume between bins.
    \item $f_3(s) = \text{avgcageratio}(s)$: we prefer states that have better average cage ratio (\cref{eq:cage_ratio}) between bins.
\end{itemize}

\section{Support Planes}
\label{sec:support_planes}%
Support Planes (SP) is a constructive heuristic based on an underlying 2D-BPP heuristic which is used to generate feasible insertions inside a bin starting from a set of items to pack.
Since insertions must be feasible, SP maintains an internal structure to facilitate feasibility checks.
The idea at the base of SP is to build a solution to the 3D-BPP by filling 2D planes called \textit{support planes}.

Each support plane is characterized by the tuple $(z, I_{support}, I_{upper})$ where
\begin{itemize}
    \item $z$: is the height of the plane,
    \item $I_{support}$: the set of the items that can offer support to items placed on the plane,
    \item $I_{upper}$: the set of items that will be obstacles to potential new items placed on the plane.
\end{itemize}

Every item placed in the bin can either generate a new support plane or be part of the supporting items of other planes. 
Items placed above a particular plane, such that $z_i + h_i > z$, are considered obstacles and are added to the $I_{upper}$ set.
When evaluating a new possible insertion, given a set of items to place $I$, SP selects the first feasible insertion starting from the lowest plane by using a modified version of Extreme Point in two dimensions (introduced in \citep{crainic2008extreme}).
Once no more insertions can be made on the lowest available support plane, it's removed from the set of planes.
Since insertions always happen in the lowest possible planes, the set of obstacles of those planes is composed of items that have only their top face above the $z$ of the evaluated plane, such that $z_i \le z < z_i + h_i$.

The Extreme Point (EP) heuristic evaluates the placement of rectangles in a plane based on a set of reference points with a best-fit approach. 
Each rectangle placement generates a new set of reference points which are usually introduced based on the projection of its corner points along the orthogonal axis of the plane.
The corner points of an added rectangle $r$ placed in $(x_r, y_r)$ of dimensions $(w_r, d_r)$ are the top left corner $(x_r, y_r + d_r)$ and the bottom right corner $(x_r + w_r, y_r)$.
In our version of the algorithm, the corner points of each item are introduced without projecting them to increase the likelihood of evaluating placements that verify the support constraint.
Placements follow a first-fit approach where the algorithm selects the first point closest to the origin where a rectangle can fit with or without rotations.
In order to facilitate the evaluation of reference points with support, we also generate a reference point in the bottom left corner of each item that belongs to the set of supporting items $I_{support}$.
When a reference point is used for a placement, it is then removed from the pool of reference points.
Before evaluating placements, the item to place are ordered based on their area.
New planes have the origin of space $(0,0)$ as an available reference point.

Since reference points are usually ordered based on the euclidean distance from the bottom left corner of the plane and the corner points are usually generated and projected towards the origin of each axis, the placements over one plane are usually biased towards the bottom left corner.
To address the problem, we evaluate four instances of EP where each has a different coordinate change applied to every item that moves the plane's origin to each corner of the bin.
This addition is based on similar approaches from the literature where it is usually used to more uniformly fill the space (ex. \citep{GAJDA2022102559}) and was verified to yield better cage ratio results in our internal testing.
%TODO: Check the above

The EP procedure is called for each item to pack on a given plane. 
In order to produce a valid insertion, every item in the insertion shouldn't overlap each other (as stated in \cref{def:insertion}).
Since the AABB tree for a given state is shared by each evaluation of a possible insertion, it can't be modified to account for temporary placements of items.
This means that we need to keep a temporary AABB tree updated composed of the items that are part of the current insertion $T^\prime$.
We can then define a function that uses the temporary tree and the feasibility function defined in \cref{sec:problem_state:feasibility} to ensure that we are producing a feasible insertion as \cref{eq:ep_can_pack}.
\begin{equation}
    \label{eq:ep_can_pack}
    EPCanPack(i, I_{support}, T, T^\prime) = IsFeasible(i, I_{support}, T) \land \lnot AABBOverlaps(i, T^\prime)
\end{equation}
A graphical representation of a support plane is shown in \cref{fig:support_planes} with the reference points available. In \cref{fig:ep_coordinate_changes} the state of two extreme point instances for the bottom left and top left coordinate changes are shown.
When a bin is opened the only support plane available is the one on the ground. 
In the figure different coordinate changes are marked with different colors.

\begin{figure}[hp]
    \centering
    \scalebox{0.9}{%
    \input{Images/support_planes}
    }
    \caption{Representation of a generic support plane with a placed item}
    \label{fig:support_planes}
\end{figure}

\begin{figure}[hp]
    \centering
    %\scalebox{0.75}{%
    \input{Images/ep_coordinate_changes}
    %}
    \caption{Extreme Point instances for some coordinate changes of \cref{fig:support_planes}}
    \label{fig:ep_coordinate_changes}
\end{figure}
%TODO: Proporre la versione ibrida maxrect/extreme points?

Given \cref{eq:ep_can_pack} to check if a considered placement would lead to a feasible insertion, the set of items to pack $I$, the AABB tree of the currently packed items $T$ and the set of currently available support planes $Z$.
The heuristic that will output the new best possible feasible insertion for the given set of items or an empty object can be summarized in alg. \ref{algo:sp_bestinsertion}. 

\input{algorithms/supportplane}
\input{algorithms/ep_insert_rect}

\paragraph*{Commit Extension}
We now describe an extension to $Commit$ (algo. \ref{algo:state_commit}) to update the structures needed by SP.

When a plane is filled, new insertions become less likely to be feasible. 
To avoid evaluating planes where no insertion is possible a mechanism to prune dead planes can be introduced.

Since best insertions for a bin are always evaluated by considering lower planes first, if all the insertions in $Expand$ (algo. \ref{algo:state_successor}) happened over a $z_{min}$ then we can safely remove the opened planes with $z < z_{min}$ for that bin.
Let us introduce a $z_{min}$ variable carried over in $q_b$ for each bin, which is updated during the $Expand$ phase with the minimum $z$ of all the insertions on bin $b$.
Once the best states are computed and $Commit$ is called we can then use its value to prune planes in each $q_b$.
Other operations are also necessary in the $Commit$ algorithm to allow SP to update its data structures accordingly to the insertion.

Given a state $s$ and an insertion $p$ where each packed item $i \in p.I$ in bin $b$ has $z_i$ within tolerance of $z$ and the minimum height for the considered bin $q_b.z_{min}$.
The algorithm which updates the structures for a given bin $b$ is represented by algorithm \ref{algo:sp_commit}.
This new algorithm can be used as the last step of the $Commit$ algorithm for each $b \in s^\prime.B$.

\input{algorithms/sp_commit}

\subsection{Sorting Insertions}
\label{ssec:scoring_insertions}%
Similarly to the sorting of states (\cref{ssec:scoring_states}), an ordering function is also needed to evaluate different insertions for the same set of items.
Given the lexicographic ordering formulation in \cref{def:lexicographic_ordering} a few new statistics can be calculated and stored inside an insertion to help in the evaluation.
By using the AABB tree which represents the bin where the insertion is going to happen $T$ it is also possible, given one of the inserted items $i \in p.I$, to define functions that use the tree to calculate usefull statistics:
\begin{itemize}
    \item $CloseItems(i, T)$: which returns the number of packed items close to $i$,
    \item $CloseSameHeight(i, T)$: which returns the number of packed items in the tree close to $i$ and with its same height,
    \item $CloseSameShape(i, T)$: which returns the number of packed items in the tree close to $i$ and with its same shape,
    \item $TotalSupportedArea(i, T)$: which returns total base area of $i$ which is supported by other items.
\end{itemize}
We can then sort an insertion $p$, given the AABB tree of the bin where the insertion will happen $T$, with a lexicographic ordering as follows:
\begin{itemize}
    \item $f_1(p) = -\sum\limits_{i \in p.I}{CloseSameShape(i, T)} - |p.I|$: maximize number of items inserted (of the same shape) that are close to already packed items of the same shape,
    \item $f_2(p) = -\sum\limits_{i \in p.I}{(w_i d_i + w_i d_i h_i)}$: maximize the sum of the area and volume of each packed item,
    \item $f_3(p) = \max\limits_{i \in p.I}(z_i + h_i)$: minimize the maximum height of the inserted items,
    \item $f_4(p) = \sum\limits_{i \in p.I}{TotalSupportedArea(i, T)}$: minimize the support area available to the inserted items,
    \item $f_5(p) = -\sum\limits_{i \in p.I}{CloseSameHeight(i, T)} - |p.I|$: maximize the number of items inserted (of the same height) that are close to already packed items of the same height,
    \item $f_5(p) = -\sum\limits_{i \in p.I}{CloseItems(i, T)} - |p.I|$: maximize the number of items inserted that are close to already packed items.
\end{itemize}
It is noted that prefering feasible insertions that minimize the supported area of each item as in $f_4$ is inspired by other works on spacing from the literature.
As shown in \citep{elhedhli2019three}, overly satisfying the support constraint can lead to unbalanced bins.
Minimizing the supported area of each item leads to minimizing the perimeter of overlap between items which in turn results in more balanced bins and with better spacing between items.