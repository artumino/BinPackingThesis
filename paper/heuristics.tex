This chapter describes a heuristic algorithm to solve the 3D bin packing problem with vertical support.
In section \ref{sec:problem_state} we describe the concepts which will be used in the algorithm, like the definition of a state, insertions, and the feasibility of a solution.
Since the 3D-BPP is NP-Hard, an exhaustive search for a solution isn't practical, so a heuristic search is conducted by combining a beam search algorithm described in \cref{sec:beamsearch} and a constructive heuristic described in \cref{sec:support_planes}.
The proposed algorithm takes in input an initial feasible state (as defined in section \ref{sec:problem_state:feasibility}), usually represented by the empty state (\ref{def:empty_state}), and outputs the best scoring state based on an ordering function defined in section \ref{ssec:scoring_states}.

\section{States}
\label{sec:problem_state}%
States or packings are partial solutions to the 3D-BPP. Since our heuristic is constructive by nature, the main idea of the algorithm is that by starting from a state representing an empty solution, we'll iteratively build new states that are always closer to a complete solution to the problem.
Given the formal definition of the problem (\ref{sec:milp}) we introduce a few new definitions to facilitate the algorithm's definition.
First, it is helpful to define a collection of items that still need to be assigned to a particular bin; this collection would then be used to track how many items still need to be placed.
Let us define the concept of unpacked items in relation to our MILP formulation.
\begin{definition}[Unpacked item]
    An item $i \in I$ is unpacked \textbf{iff}
    \begin{equation*}
        \sum_{b \in B} u_{ib} = 0
    \end{equation*}
\end{definition}

It is also assumed that variables identifying an item's position are independent between states (changes to their values in state $s$ won't affect state $s^\prime$).
In order to simplify the algorithm representation, rotations are handled by simply swapping the dimensions $w_i$ and $d_i$ of item $i \in I$ when needed.
A state $s$ can then be defined as follows:
\begin{itemize}
    \item $U$: the set of unpacked items,
    \item $B$: the set of used bins,
    \item $Q = (q_1, q_2,\dots, q_b)$: the set of supporting structures for each bin $b \in B$,
    \item $p$: the insertion pending on this state (described by def. \ref{def:insertion}).
\end{itemize}

Since the heuristic will open new bins when the already opened ones are full, the number of bins in each state can vary and isn't fixed as a parameter to the problem like in the MILP formulation.
Thanks to the newly introduced definitions, we can trivially define a function that determines if a state is a final state.
\begin{definition}
    \label{def:state_final}
    A state $s$ is final if there are no more items to pack
    \begin{equation}
        \label{algo:state_final}%
        IsFinal(s) = \left\{\begin{aligned}
            1,\hspace{0.5cm}& s.U = \emptyset \\
            0,\hspace{0.5cm}& \text{otherwise}
        \end{aligned}
        \right.
    \end{equation}
\end{definition}

The proposed heuristic also stores additional data for each opened bin, which will then be used by the constructive heuristic described in \cref{sec:support_planes}.
This additional information is stored in the set $s.Q$ so that each bin $b \in B$ has an associated supporting structure $q_b \in s.Q$.
The collection of items placed inside a bin, for example, is one piece of data that we store in this structure.
Let us then introduce the concept of packed items inside a bin.
\begin{definition}[Packed item]
    Given a state $s$ and a bin $b \in s.B$, we say that item
    \begin{equation*}
        \begin{aligned}
            i \in I \hspace{.2cm}\text{is packed in} \hspace{.2cm}b \hspace{.2cm}& \textbf{iff} \hspace{.2cm}& u_{ib} = 1
        \end{aligned}
    \end{equation*}
\end{definition}

In addition to the set of packed items, other supporting structures are needed to facilitate checks of the problem's constraints.
Given a bin $b \in s.B$ we can then define structure $q_b$ as follows.
\begin{itemize}
    \item $J$: the set of items that are packed inside $b$,
    \item $Z$: the set of planes inside $b$ (section \ref{sec:support_planes}),
    \item $T$: the AABB Tree (section \ref{sec:problem_state:aabbtree}) representing the items inside $b$.
\end{itemize}

Both sets $q_b.J$ and $q_b.T$ contain the items packed in $b$ but adding and accessing items in $q_b.J$ has a time complexity of $O(1)$ given an underlying implementation as HashSet while maintaining $q_b.T$ usually has a time complexity of $O(log(|q_b.J|))$.

\subsection{AABB Tree}
\label{sec:problem_state:aabbtree}%

To determine the feasibility of a given state, checking for overlaps with items already placed is needed.
Since every item is a cuboid and our problem formulation only allows for $90\deg$ rotations over the z-axis, each item is contained inside a bounding box, which is axis-aligned.
An adequate structure to compute overlaps is then an Axis-Aligned Bounding Box Tree (AABB Tree) \cite{bergen1997efficient}.

AABB Trees are bounding volume hierarchies typically used for fast collision detection, and they usually offer a few operations:
\begin{itemize}
    \item $AABBInsert(i)$: which allows inserting an axis-aligned box $i$ in the tree
    \item $AABBOverlaps(i)$: which allows determining if an axis-aligned box $i$ overlaps an element in the tree
    \item $AABBClosest(i, d)$: which, given an axis-aligned box $i$ and a direction \\$d \in \{ XP, XN, YP, YN, ZP, ZN \}$ along an axis, returns the closest element following that direction starting from the box $i$
\end{itemize}

If the tree is appropriately balanced, each operation, on average, has a time complexity of $O(log(n))$ where $n$ is the number of elements in the tree.
Maintaining an AABB Tree in the state allows us to do checks for feasibility during the construction of a solution (as detailed in \ref{ssec:scoring_insertions} ) and feasibility checks on the final states to allow for error detection.

\label{aabb:get_supporting}%
An additional opertation $AABBGetSupporting(i, \beta_s)$ was added to compute the set of supporting boxes of item $i$ given a tolerance $\beta_s$.
This was possible by only checking intersections over the XY-plane similarly to the $AABBOverlaps$ implementation and filtering each item by the distance with tolerance.

\subsection{Feasibility}
\label{sec:problem_state:feasibility}%
A state $s$ is feasible if the currently packed items in each bin $b \in s.B$ aren't overlapping any other item if they are all contained inside their bin and if each item is either on the ground or satisfies at least one of the support conditions (cond. \ref{support:area_support}, cond. \ref{support:vertex_support}).
Since the proposed heuristic is constructive, it is more convenient to define the concept of feasibility relative to a change in the state.
In the heuristic, we generate new states by applying insertions starting from an initial feasible one. Let us define the concept of insertion and how an insertion is feasible..
\paragraph*{Insertions}

Given a state $s$ and $b \in s.B$, an insertion of items is a set of non-overlapping items that are placed in $b$ and have their $z_i$ within tolerance from a certain $z$.
\begin{definition}[Insertion]
    \label{def:insertion}%
    Given a state $s$ and a tolerance $\beta_s$ we define an insertion or placement $p$ a tuple $(b, I)$ where $b$ is a bin, and $I$ is a set of non-overlapping items that are going to be packed in $b$ such that, $I \subseteq s.U \land \exists z (z \in \mathbb{Z} \land \forall i ( i \in I \land |z_i - z| \le \beta_s))$
\end{definition}
\begin{observation}
    \label{oss:state_bin_open}
    Given a state $s$ and an insertion $p = (b, \emptyset)$ where $b \notin s.B$, $p$ is an insertion which will open bin $b$ in $s$.
\end{observation}

\begin{definition}[Next]
    \label{def:state_next}%
    Let $p$ be an insertion over a state $s$ we can then define $s^\prime = Next(s, p)$ as the "copy" of state $s$ with $s^\prime.p = p$. And $p$ is then a pending insertion on $s^\prime$.
\end{definition}

We can evaluate the changes to the score of a state based on its pending insertion. 
In this way, we don't have to update all the structures for every evaluated state. 
In addition, this property let us do fewer memory clones of states that would have been discarded either way (as seen in \cref{sec:beamsearch}). 
We can then define an algorithm that applies a pending insertion $p$ on a given state $s$ with the help of a function $OpenBin(b)$ which initializes a new structure $q_b$ with every element at its empty value.
The proposed algorithm is shown in \ref{algo:state_commit}.

\input{algorithms/state_commit}

\paragraph*{Insertion feasibility}
An insertion $p = (b, I)$ that is pending on a given state $s$ is feasible if every inserted item $i \in p.I$ satisfies the constraint of non-overlap (\ref{cons:no_overlap}), the constraint of support (\ref{cons:every_item_is_supported}) and if it is placed within the size of the given bin.
Given an item from the set of the inserted items $i \in p.I$, and the AABB tree for bin $p.b$ in the current state $q_b.T$ as $T$.
Let $I_{\text{support}}$ be the set of items that could support item $i$ when placed in the bin, which could be saved in an appropriate structure or computed through the AABB tree as defined in \cref{aabb:get_supporting}.

Let $HasSupport(i, I_{\text{support}})$ be the function that returns true if the considered item would verify at least one of the conditions of support (\ref{support:area_support} or \ref{support:vertex_support}) or false otherwise.
We can define a function $IsFeasible(i, I_{\text{support}}, T)$ which returns true if the insertion of $i$ in bin $b$ for state $s$ is feasible and false otherwise. 
If every item $i \in p.I$ is feasible and every item in $I$ isn't overlapping the others, then insertion $p$ is feasible.
In case some items in $p$ aren't feasible we can always define a function $RemoveInfeasibleItems(p, I_{\text{support}}, T)$ which removes every unfeasible item and returns a new insertion $p^\prime = (b, I^\prime)$ where $I^\prime = p.I \setminus \{i \in p.I : \lnot IsFeasible(i, I_{\text{support}}, T)\}$. \label{algo:remove_infeasible}

Checking if a state is feasible can then be done by iteratively applying all the insertions ordered by z and updating the proper trees, or starting from an already built tree and computing the set $I_{\text{support}}$ for each item through the tree as defined in \ref{aabb:get_supporting}.
\begin{proposition}
    \label{prop:feasible_expansion}
    A state $s^\prime$ derived by committing a feasible insertion $p$ to a feasible state $s$ is feasible.
\end{proposition}

\begin{observation}
    \label{def:empty_state}
    We can always define the empty state $s_e$ where \begin{equation*}
        \left\{ 
            \begin{aligned}
            s_e.U & = I \\
            s_e.Q & = \emptyset \\
            s_e.B & = \emptyset
            \end{aligned}
        \right.
    \end{equation*}
    and it is always feasible
\end{observation}

\subsection{State Hashing}
\label{sec:state_uniqueness}%
From a given state, it's possible to apply two different sequences of insertions and end up with two states that have all the items in the same positions.
This undesirable behavior was observed during our computational experiments.
A hashing mechanism needs to be introduced to enable checking if two states are likely the same in constant time.
In a state $s$ we can identify a packed item $i \in I$ in a given position $(x_i, y_i, z_i)$ with its given dimensions $(w_i, d_i, z_i)$ in a given bin $b \in s.B$ with a non-commutative hashing function $hash_{nc}$. 
The resulting hash $hash_{ib} = hash_{nc}(b, x_i, y_i, z_i, w_i, d_i, h_i)$ can identify every similar packing of an item of the same shape in that specific bin spot.
Since $hash_{ib}$ identifies one item with the shape of $i$ in the same spot as $i$, we can use a commutative function to combine every hash for every packed item in every bin to ignore the order with which items were added to the solution.
The combined hash can then be saved inside the state structure as follows. 
\begin{equation}
    s.hash = \sum\limits_{b \in s.B}{\sum\limits_{i \in q_b.J}{hash_{ib}}}
\end{equation}
In our tests, by filtering states with the proposed hash as seen in algo. \ref{algo:beamsearch}, with a simple 64-bit hashing function, this mechanism allowed us to filter out almost all equal states between iterations with a low amount of collisions.
Since the combining of hashes is a simple sum with modulus, the hashing of the state can also be kept updated in constant time at each iteration by simply adding the inserted hashes in the $Commit$ function (algo. \ref{algo:state_commit}).

%TODO: Do a grammar pass
\section{Beam Search}
\label{sec:beamsearch}%
%TODO: maybe add info on literature  (search about Bisiani)
Beam Search (BS) is a heuristic tree search algorithm designed for systems with limited memory where expanding every possible node is unfeasible.
The idea behind BS is to conduct an iterative truncated breadth-first search where, at each iteration, only a limited number of $k$ nodes is expanded.
After the expansion, every new node needs to be evaluated and sorted to prune the number of nodes down to the $k$ best ones. The algorithm keeps exploring until no further node can be expanded.

To perform BS one must define the node structure, an expansion function to generate new nodes from existing ones, a ranking between nodes, and a function to determine if a node is final.

A node in the tree can be represented as the state in \cref{sec:problem_state} and \cref{algo:state_final} can be used to determine if a state is final. We also know that a new state $s^\prime$ derived by $s$ by applying a feasible insertion $p$ can be computed as in \cref{def:state_next}.
This state expansion procedure, with the exception of empty insertions, will generate new states in our tree which will add a positive number of bins or packed items to the solution so, eventually, it will generate a final state.

If the starting state for the search is feasible every new state generated will be feasible and if a final state is found it will be feasible ( \cref{prop:feasible_expansion}).
We also note that starting from state $s$ the time complexity to compute feasible insertions can be lower than the complexity required to update the structures that will be used for further expansions (AABB Tree insertion and balancing, memory cloning, etc.) so we modified the standard BS algorithm to separate the expansion phase from the commit phase.
As noted in \cref{sec:state_uniqueness}, since by evaluating different insertions on different states it is possible to end up having two equal states, a filtering mechanism should be introduced.
During each iteration, it is possible to keep the hashes of the best scoring selected states in a HashSet and discard new states with the same hash.

Given a set of initial states $S^0$ and the number of best states to expand at each iteration $k$, the described BS can be represented by algorithm \ref{algo:beamsearch}.
As observed in \cref{def:empty_state}, it's possible to start the search from $S^0 = \{ s_e \}$.

\input{algorithms/beamsearch}

\paragraph*{State Expansion}

An expansion of a state $s$ can be seen as a new set of states $S_{new}$ derived by a set of feasible insertions.
In order to determine these insertions, an underlying heuristic is used (described in \cref{sec:support_planes}).

The main idea in this phase of the algorithm is to find feasible insertions in all the bins at the lowest possible height for items that still need to be packed.
To reduce the number of possible expansions to evaluate we limit the search to insertions of items with unique shapes.
With a similar concept to the one used in \cref{sec:state_uniqueness}, an hash for each item's dimensions can be computed on the fly or pre-computed as a problem's parameter.
Given each item's hash we can then group items that have the same shape.
The evaluation of new insertions can then be done with two different approaches:
\begin{itemize}
    \label{def:placement_modes}%
    \item \textbf{Single Placement}: where we evaluate only the possible insertion of a single item per item type, which would generate insertions of at most 1 item,
    \item \textbf{Group by Hash}: where we evaluate the biggest possible insertion of a group of items of the same shape, which would generate insertions of at most the size of the group of items with the same shape.
\end{itemize}
Creating insertions of groups of similar items is usually used in Pallet Loading Problems (as for ex. \cite{elhedhli2019three}) to create better bases of support for upper layers.
With a similar intuition, the idea of placing groups of items of the same shape is to facilitate the creation of uniform planes (not necessarily layers) to use for further insertions.

Given a set of items $I$ and a tolerance $\beta_s$ we can introduce an algorithm to group them by their shape and produce a set $G$ of tuples $(h, I^\prime)$ where $h$ is the hash summurizing the shape of the group and $I^\prime$ is the set of items grouped as in algo. \ref{algo:group_by_hash}.
Once items are grouped by shape the best insertion for each class of items can be computed for each open bin. If no insertion is possible in any bin, then the only viable insertion is the bin opening insertion (\cref{oss:state_bin_open}).
The described procedure is detailed in algo. \ref{algo:state_successor}, which can be modified with minor changes to limit the number of items to consider when in single placement mode.

\input{algorithms/state_successor}
\input{algorithms/group_by_height}


\subsection{Scoring States}
\label{ssec:scoring_states}%
In order to sort states, a scoring function needs to be defined over them.
Since the scoring of the states is what will influence the final solution the most, parameters that are directly related to minimizing the objective function are selected.

In the proposed solution to handle multiple objective functions, lexicographic ordering is used.
\begin{definition}
    \label{def:lexicographic_ordering}
    Let $f_1(s), f_2(s), f_i(s), \dots, f_n(s)$ be objective functions ordered by precedence based on index $i \in \mathbb{Z}$, then 
    \begin{equation*}
        s < s^\prime \hspace{.2cm} \textbf{iff} \hspace{.2cm} \exists j \in \mathbb{Z} : \left\{
            \begin{aligned}
                f_j(s) < f_j(s^\prime) & \\
                f_k(s) = f_k(s^\prime) &,\hspace{.5cm} \forall k \in \mathbb{Z} : 0 \le k < j 
            \end{aligned}
        \right.
    \end{equation*}
\end{definition}

Scoring metrics for each state $s$ that we want to evaluate can then be computed in the $Next$ algorithm by considering the contents of the pending insertions and updating each parameter differentially.

The defined ordering utilized is the following:
\begin{itemize}
    \item $f_1(s) = -|s.B|$: we prefer states that opened fewer bins.
    \item $f_2(s) = \text{avgvol}(s)$: we prefer states that have packed more average volume between bins.
    \item $f_3(s) = \text{avgcageratio}(s)$: we prefer states that have better average cage ratio (\cref{eq:cage_ratio}) between bins.
\end{itemize}

\section{Support Planes}
\label{sec:support_planes}%
Support Planes (SP) is a constructive heuristic based on an underlying 2D-BPP heuristic which is used to evaluate feasible insertions inside a bin starting from a set of items to pack.
Since insertions must be feasible, SP maintains an internal structure to facilitate feasibility checks.
The idea at the base of SP is to build a solution to the 3D-BPP by filling 2D planes called \textit{support planes}.

Each support plane is characterized by the tuple $(z, I_{support}, I_{upper})$ where
\begin{itemize}
    \item $z$: is the height of the plane,
    \item $I_{support}$: the set of the items that can offer support to items placed on the plane,
    \item $I_{upper}$: the set of items that will be obstacles to potential new items placed on the plane.
\end{itemize}

Every item placed in the bin can either generate a new support plane or be part of the supporting items of other planes. 
Items placed above a particular plane, such that $z_i + h_i > z$, are considered obstacles and are added to the $I_{upper}$ set.
When evaluating a new possible insertion, given a set of items to place $I$, SP selects the first feasible insertion starting from the lowest plane by using a modified version of Extreme Point in two dimensions (introduced in \cite{crainic2008extreme}).
Once no more insertions can be made on the lowest available support plane, it's removed from the set of planes.
Since insertions always happen in the lowest possible planes, the set of obstacles of planes where new insertions can be made is composed of items that only have their top face above the $z$ of the evaluated plane, such that $z_i < z < z_i + h_i$.

The Extreme Point (EP) algorithm evaluates the placement of rectangles in a plane based on a set of reference points. 
Each rectangle placement generates a new set of reference points which are usually introduced based on the projection of its extreme points along each axis.
The extreme points of an added rectangle $r$ placed in $(x_r, y_r)$ of dimensions $(w_r, d_r)$ are the top left corner $(x_r, y_r + d_r)$ and the bottom right corner $(x_r + w_r, y_r)$.
In our version of the algorithm, the extreme points of each item are introduced without projection to increase the likelihood of evaluating placements that verify the support constraint.
If placements in a given reference point cannot be made, items can be rotated along their z-axis if they fit.
When a reference point is used for a placement, it is then removed from the pool of reference points.

Since reference points are usually ordered based on the euclidean distance from the bottom left corner of the plane and the extreme points are usually generated and projected towards the origin of each axis, the placements over one plane are usually biased towards the bottom left corner.
To address the problem, we evaluate four instances of EP where each has a different coordinate change applied to every item that moves the plane's origin to each corner of the bin.
This addition is based on similar approaches from the literature where it is usually used to more uniformly fill the space (ex. \citeauthor{GAJDA2022102559}) and was verified to yield better cage ratio results in our internal testing.
%TODO: Check the above

Elements from the collection of obstacles for a plane are considered fixed placements already made with their extreme points already added to the reference point collection; this allows us to evaluate placements near other items from different planes.
When checking for possible placements in a reference point, the feasibility check defined in \cref{sec:problem_state:feasibility} can be used to avoid selecting unfeasible insertions.
A graphical representation of a support plane is shown in \cref{fig:support_planes}. When a bin is opened the only support plane available is the one on the ground.

%TODO: Proporre la versione ibrida maxrect/extreme points?

Given a function to check the feasibility of an insertion,
and the function $ComparePacking(p, p^\prime)$ which defines a ranking over insertions in the same plane,
the SP algorithm can be written as algorithm \ref{algo:sp_bestinsertion}.

\input{algorithms/supportplane}

To evaluate a packing on a plane a heuristic to solve the 2DBPP is used with the introduction of fixed insertions which represent items on other planes that will be obstacles in the current one.

%TODO: Specify that the selected heuristic must operate with the assumption of fixed insertions

Given the dimensions of the 2D bin $(W_b, D_b)$, the set of obstacles $I_{o}$ and the set of items to pack $I_{p}$ a new insertion can be computed following algorithm \ref{algo:sp_rectpack}

\input{algorithms/sp_rectpack}

%FIXME: [G1-END]
\paragraph*{Commit Extension}
We now describe an extension to $Commit$ (algo. \ref{algo:state_commit}) to update the structures needed by SP.

When a plane is filled, new insertions become less likely to be feasible. 
To avoid evaluating planes where no insertion is possible a mechanism to prune dead planes can be introduced.

Since best insertions for a bin are always evaluated by considering lower planes first, if all the insertions in $Expand$ (algo. \ref{algo:state_successor}) happened over a $z_{min}$ then we can safely remove the opened planes with $z < z_{min}$ for that bin.
Let us introduce a $z_{min}$ variable carried over in $q_b$ for each bin, which is updated during the $Expand$ phase with the minimum $z$ of all the insertions on bin $b$.
Once the best states are computed and $Commit$ is called we can then use its value to prune planes in each $q_b$.
Other operations are also necessary in the $Commit$ algorithm to allow SP to update its data structures accordingly to the insertion.

Given a state $s$ and an insertion $p$ where each packed item $i \in p.I$ in bin $b$ has $z_i$ within tolerance of $z$ and the minimum height for the considered bin $q_b.z_{min}$.
The algorithm which updates the structures for a given bin $b$ is represented by algorithm \ref{algo:sp_commit}.
This new algorithm can be used as the last step of the $Commit$ algorithm for each $b \in s^\prime.B$.

\input{algorithms/sp_commit}

\subsection{Scoring Insertions}
\label{ssec:scoring_insertions}%