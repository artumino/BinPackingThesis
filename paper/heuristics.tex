This chapter describes a heuristic algorithm to solve the 3D bin packing problem with vertical support.
In section \ref{sec:problem_state} we describe the concepts which will be used in the algorithm, like the definition of a state, insertions, and the feasibility of a solution.
Since the 3D-BPP is NP-Hard, an exhaustive search for a solution isn't practical, so a heuristic search is conducted by combining a beam search algorithm described in \cref{sec:beamsearch} and a constructive heuristic described in \cref{sec:support_planes}.
The proposed algorithm takes in input an initial feasible state (as defined in section \ref{sec:problem_state:feasibility}), usually represented by the empty state (\ref{def:empty_state}), and outputs the best scoring state based on an ordering function defined in section \ref{ssec:scoring_states}.

\section{States}
\label{sec:problem_state}%
States or packings are partial solutions to the 3D-BPP. Since our heuristic is constructive by nature, the main idea of the algorithm is that by starting from a state representing an empty solution, we'll iteratively build new states that are always closer to a complete solution to the problem.
Given the formal definition of the problem (\ref{sec:milp}) we introduce a few new definitions to facilitate the algorithm's definition.
First, it is helpful to define a collection of items that still need to be assigned to a particular bin; this collection would then be used to track how many items still need to be placed.
Let us define the concept of unpacked items in relation to our MILP formulation.
\begin{definition}[Unpacked item]
    An item $i \in I$ is unpacked \textbf{iff}
    \begin{equation*}
        \sum_{b \in B} u_{ib} = 0
    \end{equation*}
\end{definition}

It is also assumed that variables identifying an item's position are independent between states (changes to their values in state $s$ won't affect state $s^\prime$).
In order to simplify the algorithm representation, rotations are handled by simply swapping the dimensions $w_i$ and $d_i$ of item $i \in I$ when needed.
A state $s$ can then be defined as follows:
\begin{itemize}
    \item $U$: the set of unpacked items,
    \item $B$: the set of used bins,
    \item $Q = (q_1, q_2,\dots, q_b)$: the set of supporting structures for each bin $b \in B$,
    \item $p$: the insertion pending on this state (described by def. \ref{def:insertion}).
\end{itemize}

Since the heuristic will open new bins when the already opened ones are full, the number of bins in each state can vary and isn't fixed as a parameter to the problem like in the MILP formulation.
Thanks to the newly introduced definitions, we can trivially define a function that determines if a state is a final state.
\begin{definition}
    \label{def:state_final}
    A state $s$ is final if there are no more items to pack
    \begin{equation}
        \label{algo:state_final}%
        IsFinal(s) = \left\{\begin{aligned}
            1,\hspace{0.5cm}& s.U = \emptyset \\
            0,\hspace{0.5cm}& \text{otherwise}
        \end{aligned}
        \right.
    \end{equation}
\end{definition}

The proposed heuristic also stores additional data for each opened bin, which will then be used by the constructive heuristic described in \cref{sec:support_planes}.
This additional information is stored in the set $s.Q$ so that each bin $b \in B$ has an associated supporting structure $q_b \in s.Q$.
The collection of items placed inside a bin, for example, is one piece of data that we store in this structure.
Let us then introduce the concept of packed items inside a bin.
\begin{definition}[Packed item]
    Given a state $s$ and a bin $b \in s.B$, we say that item
    \begin{equation*}
        \begin{aligned}
            i \in I \hspace{.2cm}\text{is packed in} \hspace{.2cm}b \hspace{.2cm}& \textbf{iff} \hspace{.2cm}& u_{ib} = 1
        \end{aligned}
    \end{equation*}
\end{definition}

In addition to the set of packed items, other supporting structures are needed to facilitate checks of the problem's constraints.
Given a bin $b \in s.B$ we can then define structure $q_b$ as follows.
\begin{itemize}
    \item $J$: the set of items that are packed inside $b$,
    \item $Z$: the set of planes inside $b$ (section \ref{sec:support_planes}),
    \item $T$: the AABB Tree (section \ref{sec:problem_state:aabbtree}) representing the items inside $b$.
\end{itemize}

Both sets $q_b.J$ and $q_b.T$ contain the items packed in $b$ but adding and accessing items in $q_b.J$ has a time complexity of $O(1)$ given an underlying implementation as HashSet while maintaining $q_b.T$ usually has a time complexity of $O(log(|q_b.J|))$.

\subsection{AABB Tree}
\label{sec:problem_state:aabbtree}%

To determine the feasibility of a given state, checking for overlaps with items already placed is needed.
Since every item is a cuboid and our problem formulation only allows for $90\deg$ rotations over the z-axis, each item is contained inside a bounding box, which is axis-aligned.
An adequate structure to compute overlaps is then an Axis-Aligned Bounding Box Tree (AABB Tree) \cite{bergen1997efficient}.

AABB Trees are bounding volume hierarchies typically used for fast collision detection, and they usually offer a few operations:
\begin{itemize}
    \item $AABBInsert(i)$: which allows inserting an axis-aligned box $i$ in the tree
    \item $AABBOverlaps(i)$: which allows determining if an axis-aligned box $i$ overlaps an element in the tree
    \item $AABBClosest(i, d)$: which, given an axis-aligned box $i$ and a direction \\$d \in \{ XP, XN, YP, YN, ZP, ZN \}$ along an axis, returns the closest element following that direction starting from the box $i$
\end{itemize}

If the tree is appropriately balanced, each operation, on average, has a time complexity of $O(log(n))$ where $n$ is the number of elements in the tree.
Maintaining an AABB Tree in the state allows us to do checks for feasibility during the construction of a solution (as detailed in \ref{ssec:scoring_insertions} ) and feasibility checks on the final states to allow for error detection.

\label{aabb:get_supporting}%
An additional opertation $AABBGetSupporting(i, \beta_s)$ was added to compute the set of supporting boxes of item $i$ given a tolerance $\beta_s$.
This was possible by only checking intersections over the XY-plane similarly to the $AABBOverlaps$ implementation and filtering each item by the distance with tolerance.

\subsection{Feasibility}
\label{sec:problem_state:feasibility}%
A state $s$ is feasible if the currently packed items in each bin $b \in s.B$ aren't overlapping any other item if they are all contained inside their bin and if each item is either on the ground or satisfies at least one of the support conditions (cond. \ref{support:area_support}, cond. \ref{support:vertex_support}).
Since the proposed heuristic is constructive, it is more convenient to define the concept of feasibility relative to a change in the state.
In the heuristic, we generate new states by applying insertions starting from an initial feasible one. Let us define the concept of insertion and how an insertion is feasible..
\paragraph*{Insertions}

Given a state $s$ and $b \in s.B$, an insertion of items is a set of non-overlapping items that are placed in $b$ and have their $z_i$ within tolerance from a certain $z$.
\begin{definition}[Insertion]
    \label{def:insertion}%
    Given a state $s$ and a tolerance $\beta_s$ we define an insertion or placement $p$ a tuple $(b, I)$ where $b$ is a bin, and $I$ is a set of non-overlapping items that are going to be packed in $b$ such that, $I \subseteq s.U \land \exists z (z \in \mathbb{Z} \land \forall i ( i \in I \land |z_i - z| \le \beta_s))$
\end{definition}
\begin{observation}
    \label{oss:state_bin_open}
    Given a state $s$ and an insertion $p = (b, \emptyset)$ where $b \notin s.B$, $p$ is an insertion which will open bin $b$ in $s$.
\end{observation}

\begin{definition}[Next]
    \label{def:state_next}%
    Let $p$ be an insertion over a state $s$ we can then define $s^\prime = Next(s, p)$ as the "copy" of state $s$ with $s^\prime.p = p$. And $p$ is then a pending insertion on $s^\prime$.
\end{definition}

We can evaluate the changes to the score of a state based on its pending insertion. 
In this way, we don't have to update all the structures for every evaluated state. 
In addition, this property let us do fewer memory clones of states that would have been discarded either way (as seen in \cref{sec:beamsearch}). 
We can then define an algorithm that applies a pending insertion $p$ on a given state $s$ with the help of a function $OpenBin(b)$ which initializes a new structure $q_b$ with every element at its empty value.
The proposed algorithm is shown in \ref{algo:state_commit}.

\input{algorithms/state_commit}

\paragraph*{Insertion feasibility}
An insertion $p = (b, I)$ that is pending on a given state $s$ is feasible if every inserted item $i \in p.I$ satisfies the constraint of non-overlap (\ref{cons:no_overlap}), the constraint of support (\ref{cons:every_item_is_supported}) and if it is placed within the size of the given bin.
Given an item from the set of the inserted items $i \in p.I$, and the AABB tree for bin $p.b$ in the current state $q_b.T$ as $T$.
Let $I_{\text{support}}$ be the set of items that could support item $i$ when placed in the bin, which could be saved in an appropriate structure or computed through the AABB tree as defined in \cref{aabb:get_supporting}.

Let $HasSupport(i, I_{\text{support}})$ be the function that returns true if the considered item would verify at least one of the conditions of support (\ref{support:area_support} or \ref{support:vertex_support}) or false otherwise.
We can define a function $IsFeasible(i, I_{\text{support}}, T)$ which returns true if the insertion of $i$ in bin $b$ for state $s$ is feasible and false otherwise. 
If every item $i \in p.I$ is feasible and every item in $I$ isn't overlapping the others, then insertion $p$ is feasible.
In case some items in $p$ aren't feasible we can always define a function $RemoveInfeasibleItems(p, I_{\text{support}}, T)$ which removes every unfeasible item and returns a new insertion $p^\prime = (b, I^\prime)$ where $I^\prime = p.I \setminus \{i \in p.I : \lnot IsFeasible(i, I_{\text{support}}, T)\}$. \label{algo:remove_infeasible}

Checking if a state is feasible can then be done by iteratively applying all the insertions ordered by z and updating the proper trees, or starting from an already built tree and computing the set $I_{\text{support}}$ for each item through the tree as defined in \ref{aabb:get_supporting}.
\begin{proposition}
    \label{prop:feasible_expansion}
    A state $s^\prime$ derived by committing a feasible insertion $p$ to a feasible state $s$ is feasible.
\end{proposition}

\begin{observation}
    \label{def:empty_state}
    We can always define the empty state $s_e$ where \begin{equation*}
        \left\{ 
            \begin{aligned}
            s_e.U & = I \\
            s_e.Q & = \emptyset \\
            s_e.B & = \emptyset
            \end{aligned}
        \right.
    \end{equation*}
    and it is always feasible
\end{observation}

\subsection{State Hashing}
\label{sec:state_uniqueness}%
From a given state, it's possible to apply two different sequences of insertions and end up with two states that have all the items in the same positions.
This undesirable behavior was observed during our computational experiments.
A hashing mechanism needs to be introduced to enable checking if two states are likely the same in constant time.
In a state $s$ we can identify a packed item $i \in I$ in a given position $(x_i, y_i, z_i)$ with its given dimensions $(w_i, d_i, z_i)$ in a given bin $b \in s.B$ with a non-commutative hashing function $hash_{nc}$. 
The resulting hash $hash_{ib} = hash_{nc}(b, x_i, y_i, z_i, w_i, d_i, h_i)$ can identify every similar packing of an item of the same shape in that specific bin spot.
Since $hash_{ib}$ identifies one item with the shape of $i$ in the same spot as $i$, we can use a commutative function to combine every hash for every packed item in every bin to ignore the order with which items were added to the solution.
The combined hash can then be saved inside the state structure as follows. 
\begin{equation}
    s.hash = \sum\limits_{b \in s.B}{\sum\limits_{i \in q_b.J}{hash_{ib}}}
\end{equation}
In our tests, by filtering states with the proposed hash as seen in algo. \ref{algo:beamsearch}, with a simple 64-bit hashing function, this mechanism allowed us to filter out almost all equal states between iterations with a low amount of collisions.
Since the combining of hashes is a simple sum with modulus, the hashing of the state can also be kept updated in constant time at each iteration by simply adding the inserted hashes in the $Commit$ function (algo. \ref{algo:state_commit}).

\section{Beam Search}
\label{sec:beamsearch}%
Beam Search (BS) %TODO: maybe add info on literature  (search about Bisiani)
is a heuristic tree search algorithm designed for systems with limited memory where expanding every possible node is unfeasible.
The idea behind BS is to conduct an iterative truncated breadth-first search where, at each iteration, only a limited number of $k$ nodes is expanded.
After the expansion, every new node needs to be evaluated and sorted in order to prune the number of nodes down to the $k$ best ones. The algorithm keeps exploring until no further node can be expanded.

To perform BS one must define the node structure, an expansion function to generate new nodes from existing ones, a ranking between nodes, and a function to determine if a node is final.

A node in the tree can be represented as the state in \cref{sec:problem_state} and \cref{algo:state_final} can be used to determine if a state is final. We also know that a new state $s^\prime$ derived by $s$ by applying a feasible insertion $p$ can be computed as in \cref{def:state_next}.
This state expansion procedure, with the exception of empty insertions, will generate new states in our tree which will add a positive number of bins or packed items to the solution so, eventually, it will generate a final state.

If the starting state for the search is feasible every new state generated will be feasible and if a final state is found it will be feasible ( \cref{prop:feasible_expansion}).
We also note that starting from state $s$ the time complexity to compute feasible insertions can be lower than the complexity required to update the structures that will be used for further expansions (AABB Tree insertion and balancing, memory cloning, etc.) so we modified the standard BS algorithm to separate the expansion phase from the commit phase.

Given $S^0$ the set of initial states and $k$ the number of best states to expand at each iteration, the described procedure is represented by algorithm \ref{algo:beamsearch}.
As observed in \cref{def:empty_state} it's possible to start the search from $S^0 = \{ s_e \}$.

%TODO: Remove duplicates
\input{algorithms/beamsearch}

\paragraph*{State Expansion}

An expansion of a state $s$ can be seen as a new set of states $S_{new}$ derived by a set of feasible insertions.
In order to determine these insertions, an underlying heuristic is used (described in \cref{sec:support_planes}).

%TODO: Citation needed? Maybe search in martello, vigo
%TODO: We can call this greedy
The main idea in this phase of the algorithm is to find feasible insertions in all the bins for items that still need to be packed and that are of the same height.
With this approach, the solutions given by the algorithm will start by trying to fill lower layers with items of the same height if possible and they'll become more heterogeneous in upper layers where the classes of height will start to mix up.
The underlying heuristic will also use a scoring mechanism to select the best insertions for a given class of heights in order to avoid having too many states to sort.

Given a set of items $I$ and a tolerance $\beta_s$ we can introduce an algorithm to group them by their shap and produce a set $G$ of tuples $(h, I^\prime)$ where $h$ is the hash summurizing the shape of the group and $I^\prime$ is the set of items grouped as in algo. \ref{algo:group_by_hash}.

Once items are grouped by shape the best insertion for each class of items can be computed for each open bin. If no insertion is possible in any bin, then the only viable insertion is the bin opening insertion (\cref{oss:state_bin_open}).
The described procedure is detailed in algo. \ref{algo:state_successor}.

\input{algorithms/state_successor}
\input{algorithms/group_by_height}


\subsection{Scoring States}
\label{ssec:scoring_states}%
In order to sort states, a scoring function needs to be defined over them.
Since the scoring of the states is what will influence the final solution the most, parameters that are directly related to minimizing the objective function are selected.

In the proposed solution to handle multiple objective functions, lexicographic ordering is used.
\begin{definition}
    \label{def:lexicographic_ordering}
    Let $f_1(s), f_2(s), f_i(s), \dots, f_n(s)$ be objective functions ordered by precedence based on index $i$, then 
    \begin{equation*}
        s < s^\prime \hspace{.2cm} \textbf{iff} \hspace{.2cm} \exists j \in \mathbb{Z} : \left\{
            \begin{aligned}
                f_j(s) < f_j(s^\prime) & \\
                f_k(s) = f_k(s^\prime) &,\hspace{.5cm} \forall k \in \mathbb{Z} : 0 \le k < j 
            \end{aligned}
        \right.
    \end{equation*}
\end{definition}

Scoring metrics for each state $s$ that we want to evaluate can then be computed in the $Next$ algorithm by considering the contents of the pending insertions and updating each parameter differentially.

The defined ordering utilized is the following:
\begin{itemize}
    \item $f_1(s) = -|s.B|$: we prefer states that opened fewer bins.
    \item $f_2(s) = \text{avgvol}(s)$: we prefer states that have packed more average volume between bins.
    \item $f_3(s) = \text{avgcageratio}(s)$: we prefer states that have better average cage ratio (\cref{eq:cage_ratio}) between bins.
\end{itemize}

\section{Support Planes}
\label{sec:support_planes}%
%FIXME: [G1-BEGIN] correct grammar from now on
%TODO far scorrere meglio
Support Planes (SP) is a heuristic detailed in the following section based on an underlying 2DBPP heuristic which is used to evaluate feasible insertions starting from a given state.
Since the insertions must be feasible SP mantains an internal structure to facilitate the check for feasibility.
The idea at the base of SP is to build a solution to the 3DBPP by filling 2D planes called \textit{support planes}.

Each support plane can be characterized by the triple $S_z = (z, I_{support}, I_{upper})$ where
\begin{itemize}
    \item[--] $z$: the height of the plane 
    \item[--] $I_{support}$: the set of the items that can offer support to items placed on the plane
    \item[--] $I_{upper}$: the set of items that will be obstacles to potential new items placed on the plane %TODO: change explaination to be more faithfull to the algorithm
\end{itemize}%TODO: link to support

Let $coords$ be the set of possible coordinate changes which allow for the problem to evaluate insertions starting from different corners of the bin. %TODO: leave this here?
%TODO: Maybe explicit rotation?

Given a function $IsFeasible(i, bin, I_{support}, I_{upper}, aabb)$ which evaluates if a packing of item $i$ in bin $bin$ is feasible,
and the function $ComparePacking(p, p^\prime)$ which defines a ranking over insertions in the same plane,
the SP algorithm can be written as algorithm \ref{algo:sp_bestinsertion}.

\input{algorithms/supportplane}

To evaluate a packing on a plane a heuristic to solve the 2DBPP is used with the introduction of fixed insertions which represent items on other planes that will be obstacles in the current one.

%TODO: Specify that the selected heuristic must operate with the assumption of fixed insertions

Given the dimensions of the 2D bin $(W_b, D_b)$, the set of obstacles $I_{o}$ and the set of items to pack $I_{p}$ a new insertion can be computed following algorithm \ref{algo:sp_rectpack}

\input{algorithms/sp_rectpack}

%FIXME: [G1-END]
\paragraph*{Commit Extension}
We now describe an extension to $Commit$ (algo. \ref{algo:state_commit}) to update the structures needed by SP.

When a plane is filled, new insertions become less likely to be feasible. 
To avoid evaluating planes where no insertion is possible a mechanism to prune dead planes can be introduced.

Since best insertions for a bin are always evaluated by considering lower planes first, if all the insertions in $Expand$ (algo. \ref{algo:state_successor}) happened over a $z_{min}$ then we can safely remove the opened planes with $z < z_{min}$ for that bin.
Let us introduce a $z_{min}$ variable carried over in $q_b$ for each bin, which is updated during the $Expand$ phase with the minimum $z$ of all the insertions on bin $b$.
Once the best states are computed and $Commit$ is called we can then use its value to prune planes in each $q_b$.
Other operations are also necessary in the $Commit$ algorithm to allow SP to update its data structures accordingly to the insertion.

Given a state $s$ and an insertion $p$ where each packed item $i \in p.I$ in bin $b$ has $z_i$ within tolerance of $z$ and the minimum height for the considered bin $q_b.z_{min}$.
The algorithm which updates the structures for a given bin $b$ is represented by algorithm \ref{algo:sp_commit}.
This new algorithm can be used as the last step of the $Commit$ algorithm for each $b \in s^\prime.B$.

\input{algorithms/sp_commit}

\subsection{Scoring Insertions}
\label{ssec:scoring_insertions}%